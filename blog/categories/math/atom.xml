<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Math | Blog 1]]></title>
  <link href="http://vincenttam.github.io/blog/categories/math/atom.xml" rel="self"/>
  <link href="http://vincenttam.github.io/"/>
  <updated>2014-11-03T22:22:06+08:00</updated>
  <id>http://vincenttam.github.io/</id>
  <author>
    <name><![CDATA[Vincent Tam]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    
      <title type="html"><![CDATA[Understood Power Means Inequality for Integer Powers]]></title>
      <link href="http://vincenttam.github.io/blog/2014/10/25/understood-power-means-inequality-for-integer-powers/"/>
    
    <updated>2014-10-25T18:02:53+08:00</updated>
    <id>http://vincenttam.github.io/blog/2014/10/25/understood-power-means-inequality-for-integer-powers</id>
    
      <content type="html"><![CDATA[<p>I’ve learnt the AM–GM–HM inequality when I was a secondary school
student.</p>

<p>\[
  \frac{\sum_{i=1}^n x_i}{n} \ge \sqrt[n]{\prod_{i=1}^n x_i} \ge
  \frac{n}{\sum_{i=1}^n x_i^{-1}}
\]</p>

<p>But I didn’t know how to generalise it to integer power $s$.  That is,
if $k$ and $m$ are positive integers such that $k \le m$, then we have</p>

<p>\[
  \left( \frac{\sum_{i=1}^n x_i^k}{n} \right)^{\frac{1}{k}} \le
  \left( \frac{\sum_{i=1}^n x_i^m}{n} \right)^{\frac{1}{m}}.
\]</p>

<p>I read the proof in Wikipedia, and got stuck in the first step.</p>

<p>\[
  \frac{\sum_{i=1}^{n}w_{i}x_{i}^{k}}{\sum_{i=1}^{n}w_{i}x_{i}^
  {k-1}} \le \frac{\sum_{i=1}^{n}w_{i}x_{i}^{k+1}}{\sum_{i=1}^{n}
  w_{i}x_{i}^{k}},
\]</p>

<p>I quickly realised that $w_i = 1/n$ in this case.  Even though I know
that the above inequality is eqivalent to</p>

<p>\[
  \left( \sum_{i=1}^n w_{i}x_{i}^{k} \right)^2 \le
  \left( \sum_{i=1}^n w_{i}x_{i}^{k-1} \right)
  \left( \sum_{i=1}^n w_{i}x_{i}^{k+1} \right),
\]</p>

<p>At the first glance, I didn’t know how to relate this to the famous
Cauchy–Schwartz inequality.</p>

<p>\[
  \left( \sum_{i=1}^n a_{i}b_{i} \right)^2 \le
  \left(\sum_{i=1}^n a_{i}^2\right)
  \left(\sum_{i=1}^n b_{i}^2\right)
\]</p>

<p>Actually, setting $a_i = \sqrt{w_{i}x_{i}^{k-1}}$ and $b_i =
\sqrt{w_{i}x_{i}^{k+1}}$ will do.</p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[A Fake Function]]></title>
      <link href="http://vincenttam.github.io/blog/2014/09/07/a-fake-function/"/>
    
    <updated>2014-09-07T14:16:31+08:00</updated>
    <id>http://vincenttam.github.io/blog/2014/09/07/a-fake-function</id>
    
      <content type="html"><![CDATA[<p>Half a year ago, when I heard the concept of <strong>well-defined
functions</strong>, I <em>wasn’t</em> familiar with it.</p>

<p>I’ve just worked out a problem, and got more idea about that concept.
The problem should be quite easy.  It asks readers to show that if
$\langle G, * \rangle$ is a group, $g \in G$ and $\varphi_g: G \to G$
is a mapping defined by $\varphi_g (x) = g * x * g^{-1}$, then
$\varphi_g: G \to G$ is an automorphism.  However, I misunderstood
the wordings in the question, and attempted to prove that the binary
structure $\langle \{\varphi_g \mid g \in G\},\circ \rangle$ is
isomorphic to $\langle G, * \rangle$, where $\circ$ denotes the
composition of functions.  As a result, I let $\phi: \{\varphi_g
\mid g \in G\} \to G$ be a mapping defined by $\phi(\varphi_g) = g$.
The associativity, existence of identity element and existence of
inverse of the binary structure can be easily verified.  By the very
definition of $\phi$, it seems that its surjectivity is very obvious.
I continued to write “injectivity of $\phi$ is also obvious.”</p>

<p>\[
\phi(\varphi_{g_1}) = \phi(\varphi_{g_2}) \iff g_1 = g_2
  \implies \varphi_{g_1} = \varphi_{g_2}
\]</p>

<p>I tried to turn the above rightward double arrow ‘$\implies$’ into a
double-headed one.  If I <em>couldn’t</em> do so, it means that
$\phi(\varphi_{g_1}) = \phi(\varphi_{g_2})$, though $g_1 \neq
g_2$.  I realised that I need to check whether $\phi$ was
<em>well-defined</em>.  As a result, I wasted an hour on some equations.
Suddenly, I stopped substituting $x = g_1$ or $x = g_2$ into
$\varphi_{g_1} (x) = \varphi_{g_2} (x)$.  Instead I took $\langle
G, * \rangle = \langle \reals, \cdot \rangle$ and realized what I just
did was a waste of time.</p>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Weaker Group Axioms]]></title>
      <link href="http://vincenttam.github.io/blog/2014/09/06/weaker-group-axioms/"/>
    
    <updated>2014-09-06T11:12:06+08:00</updated>
    <id>http://vincenttam.github.io/blog/2014/09/06/weaker-group-axioms</id>
    
      <content type="html"><![CDATA[<p>The following axioms seem to be weaker.</p>

<p>Let $G$ be a set, and $*: G \times G \to G$ be a binary operation.</p>

<dl>
  <dt>Associativity</dt>
  <dd>$\forall a,b,c \in G, (a * b) * c = a * (b * c)$</dd>
  <dt>Existence of <em>left</em> identity</dt>
  <dd>$\exists e \in G \text{ s.t. } \forall a \in G, e * a = a$</dd>
  <dt>Existence of <em>left</em> inverse</dt>
  <dd>$\forall a \in G, \exists a^{-1} \in G \text{ s.t. } a^{-1} * a =
e$</dd>
</dl>

<p>Claim: They’re actually <em>equivalent</em> definition of a group.</p>

<!-- more -->

<p><em>Proof</em></p>

<dl>
  <dt>Existence of inverse</dt>
  <dd>We try to show that a left inverse of a group element is <em>also</em> a
right inverse of the group element.

    <p>$\forall a \in G,$
\[
\begin{split}
a * a^{-1} &amp;= e * (a * a^{-1}) &amp;\qquad \text{(existence of left
identity)}&#92;\<br />
&amp;= ((a^{-1})^{-1} * a^{-1}) * (a * a^{-1}) &amp;\qquad \text{(existence
of left identity of $a^{-1}$)}&#92;\<br />
&amp;= (((a^{-1})^{-1} * a^{-1}) * a) * a^{-1} &amp;\qquad
\text{(associativity)}&#92;\<br />
&amp;= ((a^{-1})^{-1} * (a^{-1} * a)) * a^{-1} &amp;\qquad
\text{(associativity)}&#92;\<br />
&amp;= ((a^{-1})^{-1} * e) * a^{-1} &amp;&#92;\<br />
&amp;= (a^{-1})^{-1} * (e * a^{-1}) &amp;\qquad
\text{(associativity)}&#92;\<br />
&amp;= (a^{-1})^{-1} * a^{-1} &amp;&#92;\<br />
&amp;= e &amp;
\end{split}
\]
∴$\forall a \in G, \exists a^{-1} \in G \text{ s.t. } a * a^{-1} =
e = a^{-1} * a.$</p>
  </dd>
  <dt>Existence of identity</dt>
  <dd>Similarly, we try to show that a left identity is <em>also</em> a right
identity.

    <p>$\forall a \in G,$
\[
\begin{split}
a * e &amp;= a * (a^{-1} * a) &amp;\qquad \text{(existence of inverse of
$a$)}&#92;\<br />
&amp;= (a * a^{-1}) * a &amp;\qquad \text{(associativity)}&#92;\<br />
&amp;= e * a &amp;&#92;\<br />
&amp;= a&amp;
\end{split}
\]
∴$\exists e \in G \text{ s.t. } \forall a \in G, a * e = e * a =
a$.</p>
  </dd>
</dl>

<h2 id="an-application-in-secondary-school-mathematics">An application in secondary school mathematics</h2>

<p>In high school, to show that $B \in M_{n \times n}(\reals)$ is an
inverse of $A \in M_{n \times n}(\reals)$<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>, one is taught to show
<em>both</em> $AB = I$ and $BA = I$.  Calculating $AB$ and $BA$ is hard in
general.</p>

<p>Taking $G = \GL(n,\reals)$ and regard $*$ as matrix multiplication,
one can just show that $AB = I$ by direct calculation and then
conclude that $BA = I$, and vice versa.</p>

<hr />
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>To be more general, $\reals$ can be replaced with $\fields$. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Error Bound of the Fixed Point of Contraction Mappings]]></title>
      <link href="http://vincenttam.github.io/blog/2014/08/11/error-bound-of-the-fixed-point-of-contraction-mappings/"/>
    
    <updated>2014-08-11T01:32:23+08:00</updated>
    <id>http://vincenttam.github.io/blog/2014/08/11/error-bound-of-the-fixed-point-of-contraction-mappings</id>
    
      <content type="html"><![CDATA[<p>This afternoon, I read the proof of Banach fixed-point theorem in
<em>Wikipedia</em>.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>  It’s said that</p>

<p>\begin{equation}
  d(x^*,x_n) \le \frac{q^n}{1 - q} d(x_1,x_0).
  \label{eq:inf_err}
\end{equation}</p>

<p>In the proofs for the lemmas, I could only find something like $x_k$
inside the brackets, but <em>not</em> $x^*$.  Thus, I <em>couldn’t</em> figure out
how one can derive inequality \eqref{eq:inf_err} from an inequality
derived in the proof of Lemma 2.</p>

<p>\begin{equation}
  d(x_m,x_n) \le \frac{q^n}{1 - q} d(x_1,x_0),
  \text{ where } m &gt; n.
  \label{eq:finite_err}
\end{equation}</p>

<p>I googled for some notes, and found one which told me to take the
limit of the L.H.S. of inequality \eqref{eq:finite_err} as $m \to
\infty$.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> After looking at Corollary 2.4 in the PDF file in
footnote #2 for a while, I know what I’ve missed.</p>

<p>If $\left\{ p_k \right\}$ converges to $p$,</p>

<p>\begin{equation}
  \lim_{k \to \infty} d(p_k,q) = d(p,q)
    = d\left(\lim_{k \to \infty} p_k,q \right)
  \label{eq:dist_limit}
\end{equation}</p>

<p>That’s why I wrote the <a href="/blog/2014/08/10/limit-of-distances-in-metric-spaces/" title="Limit of Distances in Metric Spaces">previous post</a>.</p>

<p>With equation \eqref{eq:dist_limit}, I can now derive
\eqref{eq:inf_err} from \eqref{eq:finite_err}.</p>

<p>$\displaystyle \because \lim_{k \to \infty} x_k = x_*$</p>

<p>\[
\begin{aligned}
d(x^*,x_n) =&amp; d\left( \lim_{k \to \infty} x_k,x_n\right) &#92;\<br />
=&amp; \lim_{k \to \infty} d(x_k,x_n) &#92;\<br />
\le&amp; \lim_{k \to \infty} \frac{q^n}{1 - q} d(x_1,x_0) \qquad
  \text{(by \eqref{eq:finite_err})} &#92;\<br />
=&amp; \frac{q^n}{1 - q} d(x_1,x_0)
\end{aligned}
\]</p>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">

      <p>Banach fixed-point theorem.  (2014, July 15).  In <em>Wikipedia, The
Free Encyclopedia</em>.  Retrieved 17:34, August 10, 2014, from
<a href="http://en.wikipedia.org/w/index.php?title=Banach_fixed-point_theorem&amp;oldid=617083697">http://en.wikipedia.org/w/index.php?title=Banach_fixed-point_theorem&amp;oldid=617083697</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">

      <p>Conrad, K.  (2014).  The contraction mapping theorem.  <em>Expository
paper.  University of Connecticut, College of Liberal Arts and
Sciences, Department of Mathematics</em>.  Retrieved August 10,2014,
from
<a href="http://www.math.uconn.edu/~kconrad/blurbs/analysis/contraction.pdf">http://www.math.uconn.edu/~kconrad/blurbs/analysis/contraction.pdf</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
    
  </entry>
  
  <entry>
    
      <title type="html"><![CDATA[Limit of Distances in Metric Spaces]]></title>
      <link href="http://vincenttam.github.io/blog/2014/08/10/limit-of-distances-in-metric-spaces/"/>
    
    <updated>2014-08-10T20:35:40+08:00</updated>
    <id>http://vincenttam.github.io/blog/2014/08/10/limit-of-distances-in-metric-spaces</id>
    
      <content type="html"><![CDATA[<p>Let $X$ be a metric space and $q \in X$.  Suppose that sequence
$\left\{ p_k \right\}$ in $X$ converges to a point $p$ in $X$.
Then, $\left\{ d(p_k,q) \right\}$ converges to $d(p,q)$.</p>

<p>\begin{align}
  &amp; \therefore \forall \varepsilon \exists N \forall k (k \ge N
  \implies d(p_k,p) &lt; \varepsilon) \label{eq2} &#92;\<br />
  &amp; \abs{d(p_k,q) - d(p,q)} &lt; \varepsilon &#92;\<br />
  &amp; \iff d(p_k,q) - d(p,q) &lt;
  \varepsilon \land d(p,q) - d(p_k,q) &lt; \varepsilon \notag &#92;\<br />
  &amp; d(p_k,q) - d(p,q) \le d(p,p_k) \iff d(p_k,q) \le
  d(p,q) + d(p,p_k) \label{eq4} &#92;\<br />
  &amp; d(p,q) - d(p_k,q) \le d(p,p_k) \iff d(p,q) \le
  d(p_k,q) + d(p,p_k) \label{eq5}
\end{align}</p>

<p>\eqref{eq4}, and \eqref{eq5} follows from the Triangular Inequality.
Apply \eqref{eq2} to \eqref{eq4} and \eqref{eq5} to finish the proof.
Q.E.D.</p>

<p>Remark: Quantifications similar to \eqref{eq2} can be found in
<a href="https://en.wikipedia.org/wiki/Uniform_continuity#Local_continuity_versus_global_uniform_continuity">Wikipedia</a>’s entry for uniform continuity.</p>

]]></content>
    
  </entry>
  
</feed>
